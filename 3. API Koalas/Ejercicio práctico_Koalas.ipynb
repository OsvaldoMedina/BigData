{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Práctico de Koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* !pip install databricks\n",
    "* !pip install koalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterable' from 'collections' (c:\\Users\\Osvaldo\\.conda\\envs\\bigdata\\lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Osvaldo\\Documents\\3. Projectos Visual Studio\\BigData\\3. API Koalas\\Ejercicio práctico_Koalas.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Osvaldo/Documents/3.%20Projectos%20Visual%20Studio/BigData/3.%20API%20Koalas/Ejercicio%20pr%C3%A1ctico_Koalas.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Osvaldo/Documents/3.%20Projectos%20Visual%20Studio/BigData/3.%20API%20Koalas/Ejercicio%20pr%C3%A1ctico_Koalas.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Osvaldo/Documents/3.%20Projectos%20Visual%20Studio/BigData/3.%20API%20Koalas/Ejercicio%20pr%C3%A1ctico_Koalas.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Osvaldo\\.conda\\envs\\bigdata\\lib\\site-packages\\databricks\\koalas\\__init__.py:74\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease explicitly unset \u001b[39m\u001b[39m'\u001b[39m\u001b[39mARROW_PRE_0_15_IPC_FORMAT\u001b[39m\u001b[39m'\u001b[39m\u001b[39m environment variable in both \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdriver and executor sides. It is required to set this environment variable only \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhen you use pyarrow>=0.15 and pyspark<3.0.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     73\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframe\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[1;32m---> 74\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m \u001b[39mimport\u001b[39;00m Index, MultiIndex\n\u001b[0;32m     75\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseries\u001b[39;00m \u001b[39mimport\u001b[39;00m Series\n\u001b[0;32m     76\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypedef\u001b[39;00m \u001b[39mimport\u001b[39;00m pandas_wraps\n",
      "File \u001b[1;32mc:\\Users\\Osvaldo\\.conda\\envs\\bigdata\\lib\\site-packages\\databricks\\koalas\\indexes.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframe\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmissing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m \u001b[39mimport\u001b[39;00m _MissingPandasLikeIndex, _MissingPandasLikeMultiIndex\n\u001b[1;32m---> 51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mseries\u001b[39;00m \u001b[39mimport\u001b[39;00m Series, _col\n\u001b[0;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m     compare_allow_null,\n\u001b[0;32m     54\u001b[0m     compare_disallow_null,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     validate_bool_kwarg,\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatabricks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkoalas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minternal\u001b[39;00m \u001b[39mimport\u001b[39;00m _InternalFrame, NATURAL_ORDER_COLUMN_NAME\n",
      "File \u001b[1;32mc:\\Users\\Osvaldo\\.conda\\envs\\bigdata\\lib\\site-packages\\databricks\\koalas\\series.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterable, OrderedDict\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m partial, wraps, reduce\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Generic, List, Optional, Tuple, TypeVar, Union\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Iterable' from 'collections' (c:\\Users\\Osvaldo\\.conda\\envs\\bigdata\\lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import databricks.koalas as ks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pser = pd.Series([1, 3, 5, np.nan, 6, 8]) \n",
    "\n",
    "## Crea una serie de Koalas con [1, 3, 5, np.nan, 6, 8]\n",
    "\n",
    "kser = ks.Series(pser)\n",
    "\n",
    "## Pasa la serie de pandas pser a Koalas con el nombre de kser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ordena kser por el index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame({'A': np.random.rand(5),\n",
    "                    'B': np.random.rand(5)})\n",
    "\n",
    "## Genera un Dataframe de Koalas con el pdf de pandas y llamalo kdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describe los datos de kdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Ordena los datos de kdf por la columna B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transpon los datos de kdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecciona las varaibles A y B de Kdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Selecciona las filas 1, 2 de kdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Selecciona las filas 0, 1 y 2 de la variable B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando funciones de Python a Koalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aplica la funcion de Python de np.cumsum a kdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eleva al cuadrado los valores de kdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obten la suma de los valores al agrupar por A y por B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generando gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed for visualizing plot on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = [0.1, 17.5, 40, 48, 52, 69, 88]\n",
    "lifespan = [2, 8, 70, 1.5, 25, 12, 28]\n",
    "index = ['snail', 'pig', 'elephant',\n",
    "         'rabbit', 'giraffe', 'coyote', 'horse']\n",
    "\n",
    "kdf = ks.DataFrame({'speed': speed,\n",
    "                   'lifespan': lifespan}, index=index)\n",
    "\n",
    "## Genera un grafico de barras con kdf y matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kdf = ks.DataFrame({\n",
    "    'sales': [3, 2, 3, 9, 10, 6, 3],\n",
    "    'signups': [5, 5, 6, 12, 14, 13, 9],\n",
    "    'visits': [20, 42, 28, 62, 81, 50, 90],\n",
    "}, index=pd.date_range(start='2019/08/15', end='2020/03/09',\n",
    "                       freq='M'))\n",
    "\n",
    "## Genera un grafico de areas con kdf y matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando SQL en Koalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kdf = ks.DataFrame({'year': [1990, 1997, 2003, 2009, 2014],\n",
    "                    'pig': [20, 18, 489, 675, 1776],\n",
    "                    'horse': [4, 25, 281, 600, 1900]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Con una consulta SQL selecciona los datos donde pig sea mayor que 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame({'year': [1990, 1997, 2003, 2009, 2014],\n",
    "                    'sheep': [22, 50, 121, 445, 791],\n",
    "                    'chicken': [250, 326, 589, 1241, 2118]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Haz un inner join entre kdf y pdf en la vriable year, selecciona el pig y el chicken\n",
    "## ordena los datos por pig y chicken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kdf = ks.DataFrame({'A': [1, 2, 3, 4, 5], 'B': [10, 20, 30, 40, 50]})\n",
    "\n",
    "## Convierete el dataframe de Koalas a Dataframe de Spark\n",
    "type(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## muestra los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
